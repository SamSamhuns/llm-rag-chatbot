"""
Get raw text from html sources

pip install requests chromedriver-autoinstaller selenium beautifulsoup4

Use requests library or the selenium with a browser driver
Using Selenium allows to bypass the scraping error generated by some sites
Chromedriver Page https://sites.google.com/chromium.org/driver/
"""
from typing import List

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
import chromedriver_autoinstaller


def get_text_from_html(html_content: str) -> str:
    """Get text from html content using bs4"""
    text_content = BeautifulSoup(html_content, 'html.parser').get_text()
    return text_content


class RequestsScraper:
    """
    requests module based simple web scraper.
    """
    def __init__(self) -> None:
        pass

    def get_html_from_url(self, url: str, timeout: int = 180) -> str:
        """
        Returns the html content from the url using requests
        Faster than selenium call but might be blocked by scraping bot blockers in websites
        """
        response = requests.get(url, timeout=timeout)
        html_content = response.content
        return html_content


class SeleniumScraper:
    """
    Selenium based web scraper. Init involves setting up chromedriver
    """
    def __init__(self, webdriver_opts: List[str] = None) -> None:
        # Check if the current version of chromedriver exists
        # & if it doesn't exist, download it automatically,
        # then add chromedriver to path
        chromedriver_autoinstaller.install()

        # start the selenium driver service
        _options = webdriver.ChromeOptions()
        # use default opts if custom list of opts is absent
        if webdriver_opts is None:
            _options.add_argument("--headless=new")
            _options.add_argument("--no-sandbox")
            _options.add_argument("--disable-dev-shm-usage")
        else:
            for opt in webdriver_opts:
                _options.add_argument(opt)
        _service = Service()
        self.driver = webdriver.Chrome(service=_service, options=_options)

    def get_html_from_url(self, url: str) -> str:
        """
        Returns the html content from the url using selenium and a browser webdriver.
        Orders of magnitude slower than requests (~5x slower)
        """
        self.driver.get(url)
        html_content = self.driver.page_source
        return html_content


if __name__ == "__main__":
    SRC_URL = "https://www.sec.gov/Archives/edgar/data/1318605/000095017023013890/tsla-20230331.htm"  # requests call is blocked
    SRC_URL = "https://github.com/SamSamhuns/tensorflow_training"
    # selenium_scraper = SeleniumScraper()
    # html = selenium_scraper.get_html_from_url(SRC_URL)
    requests_scraper = RequestsScraper()
    html = requests_scraper.get_html_from_url(SRC_URL)
    text = get_text_from_html(html)
    print(text)

    # with open("downloads/html.txt", 'w', encoding="utf-8") as fptr:
    #     fptr.write(text + "\n")
